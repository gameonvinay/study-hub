import type { TheoryQuestion } from '../../../types'

export const theoryQuestion13: TheoryQuestion = {
  "id": 13,
  "title": "Explain the Data Science Pipeline with a Diagram",
  "content": "## What is a Data Science Pipeline?\n\nA **Data Science Pipeline** is a systematic sequence of steps that transforms raw data into actionable insights and deployed models. It provides a structured framework for solving data science problems.\n\n```\nData Science Pipeline Overview:\n\n┌─────────────────────────────────────────────────────────────────────────┐\n│                        DATA SCIENCE PIPELINE                             │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                          │\n│  ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌────────┐│\n│  │  Data    │──▶│  Data    │──▶│  Feature │──▶│  Model   │──▶│ Deploy ││\n│  │Collection│   │Preparation│  │Engineering│  │ Building │   │        ││\n│  └──────────┘   └──────────┘   └──────────┘   └──────────┘   └────────┘│\n│       │              │              │              │              │     │\n│       ▼              ▼              ▼              ▼              ▼     │\n│   Raw Data      Clean Data     Features      Trained        Production │\n│                                              Model          System     │\n│                                                                          │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Stage 1: Problem Definition\n\n**Objective**: Clearly define the business problem and translate it into a data science problem.\n\n**Activities:**\n- Understand business objectives\n- Define success metrics (KPIs)\n- Identify stakeholders\n- Determine scope and constraints\n\n**Output**: Problem statement, success criteria, project plan\n\n---\n\n## Stage 2: Data Collection\n\n**Objective**: Gather relevant data from various sources.\n\n```\nData Collection Sources:\n\n┌─────────────────────────────────────────────────────────────┐\n│                    DATA SOURCES                              │\n├──────────────┬──────────────┬──────────────┬────────────────┤\n│   Internal   │   External   │   Real-time  │   Generated    │\n├──────────────┼──────────────┼──────────────┼────────────────┤\n│ • Databases  │ • Public APIs│ • IoT sensors│ • Web scraping │\n│ • Data lakes │ • Open data  │ • Streaming  │ • Surveys      │\n│ • CRM/ERP    │ • Third-party│ • Log files  │ • Experiments  │\n│ • Files      │ • Social media│• Clickstream│ • Simulations  │\n└──────────────┴──────────────┴──────────────┴────────────────┘\n```\n\n**Methods:**\n- SQL queries\n- API calls\n- File imports (CSV, JSON, XML)\n- Web scraping\n- ETL processes\n\n---\n\n## Stage 3: Data Preparation (Data Wrangling)\n\n**Objective**: Clean and transform raw data into analysis-ready format.\n\n```\nData Preparation Steps:\n\n┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐\n│  Cleaning   │──▶│ Integration │──▶│Transformation│──▶│  Reduction  │\n└─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘\n      │                 │                 │                 │\n      ▼                 ▼                 ▼                 ▼\n• Missing values   • Merge tables   • Normalization   • Sampling\n• Duplicates       • Join datasets  • Encoding        • Aggregation\n• Outliers         • Resolve        • Type conversion • Feature\n• Inconsistencies    conflicts      • Scaling           selection\n```\n\n**This stage typically takes 60-80% of project time!**\n\n---\n\n## Stage 4: Exploratory Data Analysis (EDA)\n\n**Objective**: Understand data characteristics, patterns, and relationships.\n\n```\nEDA Techniques:\n\n┌─────────────────────────────────────────────────────────────┐\n│                           EDA                                │\n├───────────────────┬─────────────────┬───────────────────────┤\n│    Univariate     │    Bivariate    │     Multivariate      │\n├───────────────────┼─────────────────┼───────────────────────┤\n│ • Histograms      │ • Scatter plots │ • Correlation matrix  │\n│ • Box plots       │ • Cross-tabs    │ • Pair plots          │\n│ • Summary stats   │ • Correlation   │ • PCA visualization   │\n│ • Distribution    │ • ANOVA         │ • Heatmaps            │\n└───────────────────┴─────────────────┴───────────────────────┘\n```\n\n**Outputs:**\n- Data insights and patterns\n- Visualizations\n- Feature recommendations\n- Initial hypotheses\n\n---\n\n## Stage 5: Feature Engineering\n\n**Objective**: Create new features and select relevant ones for modeling.\n\n```\nFeature Engineering Techniques:\n\n┌─────────────────────────────────────────────────────────────┐\n│                   FEATURE ENGINEERING                        │\n├─────────────────────────────────────────────────────────────┤\n│                                                              │\n│  Feature Creation          Feature Transformation            │\n│  ─────────────────         ───────────────────────           │\n│  • Aggregations            • Log transformation              │\n│  • Date components         • Polynomial features             │\n│  • Text features           • One-hot encoding                │\n│  • Domain features         • Label encoding                  │\n│                                                              │\n│  Feature Selection         Feature Scaling                   │\n│  ─────────────────         ───────────────                   │\n│  • Correlation analysis    • Min-Max scaling                 │\n│  • Statistical tests       • Standardization                 │\n│  • Recursive elimination   • Robust scaling                  │\n│  • Tree importance         • Normalization                   │\n│                                                              │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Stage 6: Model Building\n\n**Objective**: Train, validate, and select the best model.\n\n```\nModel Building Process:\n\n┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐\n│   Split     │──▶│   Train     │──▶│  Validate   │──▶│    Tune     │\n│   Data      │   │   Models    │   │   Models    │   │ Parameters  │\n└─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘\n      │                 │                 │                 │\n      ▼                 ▼                 ▼                 ▼\n  Train/Test       Multiple          Cross-           Grid Search\n  Split 80/20      Algorithms        Validation       Random Search\n```\n\n**Common Algorithms:**\n| Task | Algorithms |\n|------|------------|\n| Classification | Logistic Regression, Random Forest, SVM, XGBoost |\n| Regression | Linear Regression, Decision Trees, Neural Networks |\n| Clustering | K-Means, DBSCAN, Hierarchical |\n\n---\n\n## Stage 7: Model Evaluation\n\n**Objective**: Assess model performance using appropriate metrics.\n\n```\nEvaluation Metrics:\n\n┌─────────────────────────────────────────────────────────────┐\n│                   EVALUATION METRICS                         │\n├───────────────────────────┬─────────────────────────────────┤\n│      Classification       │          Regression             │\n├───────────────────────────┼─────────────────────────────────┤\n│ • Accuracy                │ • Mean Squared Error (MSE)      │\n│ • Precision               │ • Root MSE (RMSE)               │\n│ • Recall                  │ • Mean Absolute Error (MAE)     │\n│ • F1-Score                │ • R² Score                      │\n│ • AUC-ROC                 │ • Adjusted R²                   │\n│ • Confusion Matrix        │ • MAPE                          │\n└───────────────────────────┴─────────────────────────────────┘\n```\n\n---\n\n## Stage 8: Model Deployment\n\n**Objective**: Put the model into production for real-world use.\n\n```\nDeployment Architecture:\n\n┌─────────────────────────────────────────────────────────────┐\n│                   PRODUCTION ENVIRONMENT                     │\n├─────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌──────────┐    ┌──────────┐    ┌──────────┐               │\n│  │   API    │◀──▶│  Model   │◀──▶│ Database │               │\n│  │ Gateway  │    │  Server  │    │          │               │\n│  └────┬─────┘    └──────────┘    └──────────┘               │\n│       │                                                      │\n│       ▼                                                      │\n│  ┌──────────┐    ┌──────────┐                               │\n│  │ Monitor  │    │  Logging │                               │\n│  │ & Alerts │    │          │                               │\n│  └──────────┘    └──────────┘                               │\n│                                                              │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Deployment Options:**\n- REST API (Flask, FastAPI)\n- Cloud services (AWS SageMaker, Azure ML)\n- Containers (Docker, Kubernetes)\n- Edge deployment\n\n---\n\n## Stage 9: Monitoring & Maintenance\n\n**Objective**: Ensure model continues to perform well in production.\n\n**Activities:**\n- Monitor model performance\n- Track data drift\n- Retrain periodically\n- Update features\n- Handle feedback\n\n---\n\n## Pipeline Summary\n\n| Stage | Input | Output | Key Tools |\n|-------|-------|--------|----------|\n| Problem Definition | Business need | Problem statement | - |\n| Data Collection | Sources | Raw data | SQL, APIs |\n| Data Preparation | Raw data | Clean data | Pandas, Spark |\n| EDA | Clean data | Insights | Matplotlib, Seaborn |\n| Feature Engineering | Insights | Features | Scikit-learn |\n| Model Building | Features | Trained model | TensorFlow, XGBoost |\n| Evaluation | Model | Metrics | Scikit-learn |\n| Deployment | Model | API/Service | Docker, Flask |\n| Monitoring | Predictions | Alerts | MLflow, Prometheus |"
}
