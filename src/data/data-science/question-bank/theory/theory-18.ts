import type { TheoryQuestion } from '../../../types'

export const theoryQuestion18: TheoryQuestion = {
  "id": 18,
  "title": "Explain Clustering Techniques with Examples",
  "content": "## What is Clustering?\n\n**Clustering** is an unsupervised machine learning technique that groups similar data points together based on their characteristics, without predefined labels.\n\n```\nClustering Concept:\n\n┌─────────────────────────────────────────────────────────────────┐\n│  BEFORE CLUSTERING          AFTER CLUSTERING                    │\n│                                                                  │\n│    ○  ●    ○  ●           ┌─────┐  ┌─────┐  ┌─────┐            │\n│  ●   ○  ●    ○            │○ ○ ○│  │● ● ●│  │◆ ◆ ◆│            │\n│    ○    ●  ○  ●           │ ○ ○ │  │ ● ● │  │ ◆ ◆ │            │\n│  ●  ○  ●   ○              └─────┘  └─────┘  └─────┘            │\n│                           Cluster1  Cluster2  Cluster3          │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Types of Clustering\n\n| Type | Method | Example |\n|------|--------|--------|\n| **Partitioning** | Divide into K clusters | K-Means |\n| **Hierarchical** | Build tree structure | Agglomerative |\n| **Density-Based** | Find dense regions | DBSCAN |\n\n---\n\n## 1. K-Means Clustering\n\n**Concept**: Partitions data into K clusters where each point belongs to cluster with nearest centroid.\n\n```\nK-Means Steps:\n\n Step 1: Choose K=3        Step 2: Assign points     Step 3: Update centroids\n                                                      \n      ★  ★  ★              ○○○★  ●●●★  ◆◆◆★        ○○○ ★  ●●● ★  ◆◆◆ ★\n   (random centroids)      (nearest centroid)        (mean of cluster)\n                                                      \n                           Repeat until convergence\n```\n\n**Advantages**: Simple, fast, scalable\n**Disadvantages**: Must specify K, sensitive to outliers\n\n---\n\n## 2. Hierarchical Clustering\n\n**Concept**: Creates tree-like hierarchy (dendrogram).\n\n```\nDendrogram:\n\n         ┌───────┴───────┐\n     ┌───┴───┐       ┌───┴───┐\n     A   B   C       D   E   F\n     └─┬─┘           └─┬─┘\n    Cluster1        Cluster2\n```\n\n**Types**: Agglomerative (bottom-up), Divisive (top-down)\n\n---\n\n## 3. DBSCAN\n\n**Concept**: Groups densely packed points, identifies outliers.\n\n**Parameters**: eps (distance), minPts (minimum points)\n\n**Point Types:**\n- Core: ≥ minPts within eps\n- Border: Within eps of core\n- Noise: Outlier\n\n---\n\n## Comparison\n\n| Algorithm | Shape | Outliers | K Required |\n|-----------|-------|----------|------------|\n| K-Means | Spherical | Sensitive | Yes |\n| Hierarchical | Any | Moderate | No |\n| DBSCAN | Arbitrary | Handles | No |\n\n---\n\n## Applications\n\n| Domain | Use Case |\n|--------|----------|\n| Marketing | Customer segmentation |\n| Healthcare | Patient grouping |\n| Retail | Product categorization |\n| Image | Color segmentation |"
}
